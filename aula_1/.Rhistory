'rpart',      # Biblioteca de árvores
'rpart.plot', # Conjunto com Rpart, plota a parvore
'gtools',     # funções auxiliares como quantcut,
'Rmisc',      # carrega a função sumarySE para a descritiva
'scales',     # importa paletas de cores
'caret',      # Funções úteis para machine learning
'neuralnet',   # Pacote para fazer redes neurais
'gamlss',
'gamlss.add'
)
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
load('EPA_19.RData')
load('HAR_test.RData')
load('HAR_train.RData')
########################
# Instalação de pacotes
pacotes <- c('tidyverse',  # Pacote básico de datawrangling
'viridis',
'rpart',      # Biblioteca de árvores
'rpart.plot', # Conjunto com Rpart, plota a parvore
'gtools',     # funções auxiliares como quantcut,
'Rmisc',      # carrega a função sumarySE para a descritiva
'scales',     # importa paletas de cores
'caret',      # Funções úteis para machine learning
'neuralnet',   # Pacote para fazer redes neurais
'gamlss',
'gamlss.add'
)
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
load('EPA_19.RData')
load('HAR_test.RData')
load('HAR_train.RData')
# Gerar x como uma sequencia de valores entre 0 e 1
x1 <- seq(0,1, length.out=1000)
# y segue uma relação quadrática com estes parâmetros
a <- 0
b <- 12.5
c <- -10
# Gerar y
set.seed(1729)
y1 <- a + b*x1 + c*x1**2 + rnorm(length(x1), mean=0, sd=.1)
df1 <- data.frame(x1, y1) # criar um dataframe
colnames(df1) <- c('x', 'y') #renomear colunas
# Gráfico dos dados gerados
p0 <- ggplot(df1, aes(x,y)) +
geom_point(aes(colour='Observado'), alpha=.5) +
viridis::scale_color_viridis(discrete=TRUE, begin=0, end=.85, name = "Valor") +
theme_bw() +
theme(legend.position="bottom",
legend.spacing.x = unit(0, 'cm'))
p0
# Primeira rede neural
set.seed(1729)
rn0 <- neuralnet::neuralnet(y ~ x,
data=df1,
threshold = 0.01,
act.fct = 'logistic'
)
plot(rn0)
plot(rn0)
df1['pred0'] <- predict(rn0, df1)
# Valores esperados e observados
boost0_O_vs_E <- ggplot(df1, aes(x,y)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,pred0, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
# theme(legend.position="bottom") +
# guides(colour = guide_legend(label.position = "bottom")) +
labs(title="Valores observados vs esperados") +
# scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
boost0_O_vs_E
########################
# Perceptron Multicamada
set.seed(1729)
tempo_ini <- Sys.time()
rn1 <- neuralnet(y ~ x,
data=df1,
hidden = c(3,2))
tempo_fim <- Sys.time()
tempo_fim - tempo_ini
plot(rn1)
df1['pred1'] <- predict(rn1, df1)
# Valores esperados e observados
boost0_O_vs_E <- ggplot(df1, aes(x,y)) + # gráfico base >> x vs y <<
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,pred1, colour='Esperado')) + # Gráfico sobreposto >> x vs pred
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
theme(legend.position="bottom") +
# guides(colour = guide_legend(label.position = "bottom")) +
labs(title="Valores observados vs esperados") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
boost0_O_vs_E
########################
# Perceptron Multicamada
set.seed(1729)
tempo_ini <- Sys.time()
rn1 <- neuralnet(y ~ x,
data=df1,
hidden = c(3,2))
tempo_fim <- Sys.time()
tempo_fim - tempo_ini
plot(rn1)
df1['pred1'] <- predict(rn1, df1)
# Valores esperados e observados
boost0_O_vs_E <- ggplot(df1, aes(x,y)) + # gráfico base >> x vs y <<
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,pred1, colour='Esperado')) + # Gráfico sobreposto >> x vs pred
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
theme(legend.position="bottom") +
# guides(colour = guide_legend(label.position = "bottom")) +
labs(title="Valores observados vs esperados") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
boost0_O_vs_E
# carregar os dados
load(file='EPA_19.RData')
# checar a estrutura
df %>% str
# colunas quantitativas para padronizar entre 0 e 1
cols <- c("fuel_economy_combined", 'eng_disp', 'num_cyl', 'num_gears', 'batt_capacity_ah')
# função para padronizar
range01 <- function(x){(x-min(x, na.rm=TRUE))/(max(x, na.rm=TRUE)-min(x, na.rm=TRUE))}
# padronizar variaveis quantitativas
df[cols] <- lapply(df[cols], range01)
df %>% head
# criar a fórmula tipo y ~ x1 + x2 ... + xn
n <- names(df)
f_variaveis <- paste(n[-1], collapse = " + ")
f_variaveis
f <- as.formula(paste(n[1], " ~ ", f_variaveis))
f
df %>% str
m <- model.matrix(f, data = df)
m <- as.matrix(data.frame(m, df[, 1]))
#######################################
# Criar uma fórmula para a matriz m
colnames(m)[28] <- "fuel_economy_combined"
nomes <- colnames(m)
f_variaveis <- paste(nomes[-28], collapse=' + ')
f <- as.formula(paste(nomes[28], " ~ ", f_variaveis))
f
# Treinando um Linear Perceptron
set.seed(1729)
start_time <- Sys.time() # Marca o tempo de início
nn <- neuralnet(f, # Fórmula
data=m, # dados
linear.output = TRUE # indica resposta contínua
)
end_time <- Sys.time() # Marca o tempo de fim
t <- end_time - start_time # Mostra o tempo de execução
t
plot(nn)
pred <- predict(nn, m)
plot(x = pred, y = df$fuel_economy_combined)
caret::postResample(pred, df$fuel_economy_combined)
N <- nrow(m)
t.seed(1729)
start_time <- Sys.time() # Marca o tempo de início
nn <- neuralnet(f, # Fórmula
data=m, # dados
linear.output = TRUE # indica resposta contínua
)
end_time <- Sys.time() # Marca o tempo de fim
t <- end_time - start_time # Mostra o tempo de execução
t
plot(nn)
pred <- predict(nn, m)
plot(x = pred, y = df$fuel_economy_combined)
caret::postResample(pred, df$fuel_economy_combined)
N <- nrow(m)
# Treinando um Linear Perceptron
set.seed(1729)
start_time <- Sys.time() # Marca o tempo de início
nn <- neuralnet(f, # Fórmula
data=m, # dados
linear.output = TRUE # indica resposta contínua
)
end_time <- Sys.time() # Marca o tempo de fim
t <- end_time - start_time # Mostra o tempo de execução
t
plot(nn)
pred <- predict(nn, m)
plot(x = pred, y = df$fuel_economy_combined)
caret::postResample(pred, df$fuel_economy_combined)
N <- nrow(m)
nn <- neuralnet(f, # Fórmula
data=m, # dados
linear.output = TRUE # indica resposta contínua
)
plot(nn)
pred <- predict(nn, m)
plot(x = pred, y = df$fuel_economy_combined)
caret::postResample(pred, df$fuel_economy_combined)
N <- nrow(m)
nn <- neuralnet(f, data=m, hidden = c(7, 3), linear.output = TRUE)
pred <- predict(nn, m)
plot(x = pred, y = df$fuel_economy_combined)
caret::postResample(pred, df$fuel_economy_combined)
# montando um k-fold
k <- 10 #número de folds
stats <- NULL # Inicializando a qualidade dos modelos do fold
m2 = m[sample(1:nrow(m)), ] # m2 é uma permutação de m para fazermos os folds
for (i in 1:(k-1)){
ind_treino <- !seq(N)>N*(i/k) & seq(N)<=N*((i+1)/k)
ind_teste <- seq(N)>N*(i/k) & seq(N)<=N*((i+1)/k)
nn <- neuralnet(f, data=m2[ind_treino,], hidden = c(7, 3), linear.output = TRUE)
pred <- predict(nn, m[ind_teste,])
stats_tmp <- caret::postResample(pred, df$fuel_economy_combined[ind_teste])
stats <- rbind(stats, stats_tmp)
}
stats %>% colMeans()
plot(nn)
plot(nn)
# CV Grid Search para 'tunar' o parâmetro decay
nnGrid <-  expand.grid(.size=7, .decay = c(0, .005, .01, 0.015, 0.02, 0.025))
# CV Grid Search para 'tunar' o parâmetro decay
nnGrid <-  expand.grid(.size=7, .decay = c(0, .005, .01, 0.015, 0.02, 0.025))
?expand.grid
ctrl <- caret::trainControl(method='cv')
nnfit <- caret::train(f,
data=m2,
method='nnet',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
nnfit$results
modelo.final <- nnfit$finalModel
pred <- predict(modelo.final, m)
plot(x = pred, y = df$fuel_economy_combined)
caret::postResample(pred, df$fuel_economy_combined)
levels(HAR_train$y) <- c("andando",  "subindo", "descendo", "sentado",  "em_pe", "deitado")
levels(HAR_test$y) <- c("andando",  "subindo", "descendo", "sentado",  "em_pe", "deitado")
tempo_ini <- Sys.time()
rf <- randomForest::randomForest(y ~ .,
data=HAR_train[,2:563],
ntree=20,
mtry=100)
rf
tempo_fim <- Sys.time()
tempo_fim - tempo_ini
c_test <- predict(rf, HAR_test)
c_test[1:10]
avalia <- function(modelo, nome_modelo="modelo", df_treino, df_teste, vresp = "y"){
p_treino <- predict(modelo, df_treino, type='prob') # Probabilidade predita
c_treino <- predict(modelo, df_treino)              # Classificação
#Base de teste
p_teste <- predict(modelo, df_teste, type='prob')
c_teste <- predict(modelo, df_teste)
cm_treino <- confusionMatrix(c_treino, df_treino[,vresp])
print(cm_treino$table)
print(cm_treino$overall["Accuracy"])
cm_teste <- confusionMatrix(c_teste,  df_teste[,vresp])
print(cm_teste$table)
print(cm_teste$overall['Accuracy'])
}
avalia(rf, nome_modelo="rf", HAR_train, HAR_test, vresp = "y")
rf$importance
variaveis_selecionadas <- rf$importance %>% as.data.frame() %>% top_n(6) %>% row.names
variaveis_selecionadas
HAR_train$y %>% table
nnGrid <-  expand.grid(.size=6, .decay = c(0))
# nnGrid <-  expand.grid(.size=7, .decay = c(0, .005, .010, 0.015))
ctrl <- caret::trainControl(method='cv', number=4, classProbs=TRUE)
nnfit <- caret::train(y ~ .,
data=HAR_train[,c(variaveis_selecionadas, 'y')],
method='nnet',
metric='Accuracy',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=100,
verboseIter = FALSE
)
# Resultados do grid search
nnfit$results
avalia(nnfit, nome_modelo="rf", HAR_train, HAR_test, vresp = "y")
########################
# Instalação de pacotes
pacotes <- c('titanic',    # carrega a base original titanic_treino
'tidyverse',  # Pacote básico de datawrangling
'rpart',      # Biblioteca de árvores
'rpart.plot', # Conjunto com Rpart, plota a parvore
'gtools',     # funções auxiliares como quantcut,
'Rmisc',      # carrega a função sumarySE para a descritiva
'scales',     # importa paletas de cores
'caret'       # Funções úteis para machine learning
)
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
titanic %>% head
# Plotando AUC vs CP por treino e teste
#Inicializa o objeto stats, que vai guardar o AUC dos modelos
stats <- data.frame(NULL)
# Loop ao longo dos valores de CP
for (cp in cptab[2:dim(cptab)[1],'CP']){
# Treinar a árvore alterando o cp
arvore <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked,
data=treino,
method='class',
control = rpart.control(cp = cp,
minsplit = 1,
maxdepth = 30),
xval=0
)
# Avaliar a árvore na base de treino
p_treino = predict(arvore, treino)
c_treino = factor(ifelse(p_treino[,2]>.5, "Y", "N"))
aval_treino <- data.frame(obs=treino$Survived,
pred=c_treino,
Y = p_treino[,2],
N = 1-p_treino[,2]
)
aval_treino
av_treino <- twoClassSummary(aval_treino, lev=levels(aval_treino$obs))
# Avaliar base de teste
p_teste = predict(arvore, teste)
c_teste = factor(ifelse(p_teste[,2]>.5, "Y", "N"))
aval_teste <- data.frame(obs=teste$Survived,
pred=c_teste,
Y = p_teste[,2],
N = 1-p_teste[,2]
)
av_teste <- twoClassSummary(aval_teste, lev=levels(aval_teste$obs))
# Acumular as informações de cp e AUC para cada árvore
stat <- cbind(cp, ROC_treino=av_treino[1], ROC_teste=av_teste[1])
stats <- rbind(stats, stat)
}
stats
ggplot(stats) +
geom_point(aes(x=cp, y=ROC_treino, col='treino')) +
geom_point(aes(x=cp, y=ROC_teste, col='teste')) +
scale_color_viridis_d(begin=.4, end=.8) +
theme(legend.position = "bottom") +
ggtitle("Curva ROC - base de treino") +
ylab("AUC") +
labs(colour='Base')
titanic %>% head
######################################
# Vamos trabalhar com a base titanic #
# cuja fonte está na library(titanic)#
pacotes <- c('titanic',    # carrega a base original titanic_treino
'tidyverse',  # Pacote básico de datawrangling
'rpart',      # Biblioteca de árvores
'rpart.plot', # Conjunto com Rpart, plota a parvore
'gtools',     # funções auxiliares como quantcut,
'Rmisc',      # carrega a função sumarySE para a descritiva
'scales',     # importa paletas de cores
'caret'       # Funções úteis para machine learning
)
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
titanic %>% head
######################################
# Vamos trabalhar com a base titanic #
# cuja fonte está na library(titanic)#
data("Titanic")
titanic %>% head
Titanic
# Vamos criar uma base temporária para manter a base original intacta
tmp <- Titanic#titanic
tmp$survived <- as.integer(Titanic$Survived=="Y")
descritiva <- function(var){
# Sumariza a taxa de sobreviventes por categoria da variável em análise
tgc <- Rmisc::summarySE(tmp, measurevar="survived", groupvars=c(var))
ggplot(tgc) +
# Plota o gráfico de barras com as frequências
geom_bar(aes(x=tgc[,var], weight=N/891, fill=as.factor(tgc[,var]))) +
# Plota as barras de erro
geom_errorbar(aes(x=tgc[,var], y=survived, ymin=survived-se, ymax=survived+se, colour='1'), width=.1) +
# Plota as médias de cada grupo
geom_point(aes(x=tgc[,var], y=survived, colour='1', group='1')) +
# Plota as linhas que conectam as médias
geom_line(aes(x=tgc[,var], y=survived, colour='1', group='1')) +
# Escala de cores do gráfico de médias
scale_color_viridis_d(direction = -1, begin=0, end=.25) +
# Escala de cores do gráfico de barras
scale_fill_viridis_d(direction = -1, begin=.85, end=.95) +
# Estética mais 'leve' do gráfico
theme(panel.background = element_rect(fill = "white", colour = "grey", linetype = "solid"),
panel.grid.major = element_line(size = 0.15, linetype = 'solid', colour = "grey")) +
# Remove a legenda
theme(legend.position = "none") +
# Rótulo dos eixos
xlab(var) + ylab("Taxa de sobreviventes") +
# Marcas do eixo secundário
scale_y_continuous(sec.axis = sec_axis(~.*891, name = "Frequencia"), labels = scales::percent)
}
descritiva("Sex")
descritiva("Pclass")
descritiva("Embarked")
# Vamos criar uma base temporária para manter a base original intacta
tmp <- titanic
######################################
# Vamos trabalhar com a base titanic #
# cuja fonte está na library(titanic)#
#data("Titanic")
#Titanic
titanic %>% head
data(Titanic)
force(Titanic)
tmp <- Titanic
tmp
######################################
# Vamos trabalhar com a base titanic #
# cuja fonte está na library(titanic)#
library(titanic)
titanic %>% head
# Vamos criar uma base temporária para manter a base original intacta
tmp <- titanic
#data(Titanic)
titanic
data(titanic)
titanic
data(Titanic)
# Vamos criar uma base temporária para manter a base original intacta
tmp <- Titanic
tmp$survived <- as.integer(titanic$Survived=="Y")
tmp$survived <- as.integer(Titanic$Survived=="Y")
Titanic$Suvived
Titanic
tmp$survived <- as.integer(Titanic$Survived=="Yes")
descritiva <- function(var){
# Sumariza a taxa de sobreviventes por categoria da variável em análise
tgc <- Rmisc::summarySE(tmp, measurevar="survived", groupvars=c(var))
ggplot(tgc) +
# Plota o gráfico de barras com as frequências
geom_bar(aes(x=tgc[,var], weight=N/891, fill=as.factor(tgc[,var]))) +
# Plota as barras de erro
geom_errorbar(aes(x=tgc[,var], y=survived, ymin=survived-se, ymax=survived+se, colour='1'), width=.1) +
# Plota as médias de cada grupo
geom_point(aes(x=tgc[,var], y=survived, colour='1', group='1')) +
# Plota as linhas que conectam as médias
geom_line(aes(x=tgc[,var], y=survived, colour='1', group='1')) +
# Escala de cores do gráfico de médias
scale_color_viridis_d(direction = -1, begin=0, end=.25) +
# Escala de cores do gráfico de barras
scale_fill_viridis_d(direction = -1, begin=.85, end=.95) +
# Estética mais 'leve' do gráfico
theme(panel.background = element_rect(fill = "white", colour = "grey", linetype = "solid"),
panel.grid.major = element_line(size = 0.15, linetype = 'solid', colour = "grey")) +
# Remove a legenda
theme(legend.position = "none") +
# Rótulo dos eixos
xlab(var) + ylab("Taxa de sobreviventes") +
# Marcas do eixo secundário
scale_y_continuous(sec.axis = sec_axis(~.*891, name = "Frequencia"), labels = scales::percent)
}
descritiva("Sex")
descritiva("Sex")
# Load packages
library('ggplot2') # visualization
library('ggthemes') # visualization
########################
# Instalação de pacotes
pacotes <- c('titanic',    # carrega a base original titanic_treino
'tidyverse',  # Pacote básico de datawrangling
'rpart',      # Biblioteca de árvores
'rpart.plot', # Conjunto com Rpart, plota a parvore
'gtools',     # funções auxiliares como quantcut,
'Rmisc',      # carrega a função sumarySE para a descritiva
'scales',     # importa paletas de cores
'caret',      # Funções úteis para machine learning
'ggplot2',    # visualization
'ggthemes',
'scales',
'dplyr'       # data manipulation
)
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
